{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    2.2. what problems do you want to solve？\n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    2.5. How will you plan to study in this course period?\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Face recognition, Siri, self-driving cars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {we can easily share codes through Github. Most importantly it can track the code changes and do version control.}\n",
    "{Jupyter is popular because it allows literate programming. It is an excellent user interface for demonstration, research and teaching. We use Pycharm because it is a powerful IDE for development with some great functions, such as code completion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:The probability model has two parts, the sample space and probabilities. The sample space is a set of all possible outcomes of random events. Each event is associated with a probability. The probablity describes the long-term frequency of the event."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "     1. When playing blackjack, probability model can help to make a decision.\n",
    "     2. In this course, we use probability model to select the most appropriate sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Probability approximates the actual frequency of an event with infinite trials. The probability can be used to simulate whether an event occurs.}\n",
    "{Programming based parsing and pattern match is difficult because language can be creative and unstructured.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: Language model is a probability model that assigns probability to sequences of words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: speech recognition, handwriting recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 1-gram language model does not consider the history of words. The probability of a sentence is simply a product of the probabilities of all the words without conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: It does not consider any history so the appearance of one word is not affected by any other words. There is no connection between words or phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 2-gram model approximates the probability of a word given the history by calculating the conditional probability of the preceding word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "qiDaGu = '''\n",
    "sentence = people do something end\n",
    "simple_sentence = persons do objects\n",
    "people = adj* persons\n",
    "something = adj* objects\n",
    "adj* = null | adj adj*\n",
    "adj = 骄傲的 | 美若天仙的 | 血红色的 | 丢了魂的 | 隔壁的 | 腐烂的 | 未来的 | 一百万的 | 自然的\n",
    "persons = 老王 | Tony老师 | 老公 | 老板 | 小张 | 送快递的人\n",
    "do = 买了 | 喝了 | 吃了 | 丢了 | 打了 | 留下了 | 学习了\n",
    "objects = 香奈儿包包 | 包子 | 火箭 | 咖啡 | 房子 | 钱 | 儿子 | 麻将\n",
    "end = ！ | 。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "baDaYi = '''\n",
    "sentence = oh stop person do end\n",
    "oh = 我的妈呀 | 太牛逼了 | 真的吗 | 吓死我了 | 哈哈哈 | 哼 | 少来这套 | 当老娘是吃素的\n",
    "stop = ？ | ！\n",
    "person = 我 | 你 | 这人\n",
    "do = 相信 | 不信 | 服了 | 好厉害 | 也想这样 | 亲眼见过 | 不行\n",
    "end = 了。 | 吗？ | 啊！ | 的。\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from NLP Lesson-01 course notebook by Gao\n",
    "def create_grammar(grammar_str, split='=', line_split='\\n'):\n",
    "    grammar = {}\n",
    "    for line in grammar_str.split(line_split):\n",
    "        if not line.strip(): continue     # line.strip() is False when it is empty.\n",
    "        exp, stmt = line.split(split)\n",
    "        grammar[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [['people', 'do', 'something', 'end']],\n",
       " 'simple_sentence': [['persons', 'do', 'objects']],\n",
       " 'people': [['adj*', 'persons']],\n",
       " 'something': [['adj*', 'objects']],\n",
       " 'adj*': [['null'], ['adj', 'adj*']],\n",
       " 'adj': [['骄傲的'],\n",
       "  ['美若天仙的'],\n",
       "  ['血红色的'],\n",
       "  ['丢了魂的'],\n",
       "  ['隔壁的'],\n",
       "  ['腐烂的'],\n",
       "  ['未来的'],\n",
       "  ['一百万的'],\n",
       "  ['自然的']],\n",
       " 'persons': [['老王'], ['Tony老师'], ['老公'], ['老板'], ['小张'], ['送快递的人']],\n",
       " 'do': [['买了'], ['喝了'], ['吃了'], ['丢了'], ['打了'], ['留下了'], ['学习了']],\n",
       " 'objects': [['香奈儿包包'], ['包子'], ['火箭'], ['咖啡'], ['房子'], ['钱'], ['儿子'], ['麻将']],\n",
       " 'end': [['！'], ['。']]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_qiDaGu = create_grammar(qiDaGu)\n",
    "gram_qiDaGu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [['oh', 'stop', 'person', 'do', 'end']],\n",
       " 'oh': [['我的妈呀'],\n",
       "  ['太牛逼了'],\n",
       "  ['真的吗'],\n",
       "  ['吓死我了'],\n",
       "  ['哈哈哈'],\n",
       "  ['哼'],\n",
       "  ['少来这套'],\n",
       "  ['当老娘是吃素的']],\n",
       " 'stop': [['？'], ['！']],\n",
       " 'person': [['我'], ['你'], ['这人']],\n",
       " 'do': [['相信'], ['不信'], ['服了'], ['好厉害'], ['也想这样'], ['亲眼见过'], ['不行']],\n",
       " 'end': [['了。'], ['吗？'], ['啊！'], ['的。']]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_baDaYi = create_grammar(baDaYi)\n",
    "gram_baDaYi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copied from NLP Lesson-01 course notebook by Gao\n",
    "def generate_1(gram, target):\n",
    "    if target not in gram: return target # means target is a terminal expression\n",
    "    expaned = [generate_1(gram, t) for t in random.choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "送快递的人学习了隔壁的儿子。\n",
      "哈哈哈？你好厉害吗？\n",
      "小张丢了一百万的儿子。\n",
      "哈哈哈！我相信了。\n",
      "送快递的人丢了包子。\n",
      "少来这套！你不信啊！\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(generate_1(gram_qiDaGu, 'sentence'))\n",
    "    print(generate_1(gram_baDaYi, 'sentence'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "老公喝了火箭\n",
      "当老娘是吃素的\n",
      "老王留下了房子\n",
      "哈哈哈\n",
      "送快递的人学习了香奈儿包包\n",
      "当老娘是吃素的\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(generate_1(gram_qiDaGu, 'simple_sentence'))\n",
    "    print(generate_1(gram_baDaYi, 'oh'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n, gram_1=gram_qiDaGu, gram_2=gram_baDaYi, \n",
    "               t1_list=['sentence', 'simple_sentence'], t2_list=['sentence']):\n",
    "    sentences = []\n",
    "    while True:\n",
    "        sentences.append(generate_1(gram_1, random.choice(t1_list)))\n",
    "        if len(sentences) >= n: break\n",
    "        sentences.append(generate_1(gram_2, random.choice(t2_list)))\n",
    "        if len(sentences) >= n: break\n",
    "    return sentences # A list of sentences\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自然的骄傲的老板喝了自然的火箭。\n",
      "我的妈呀！这人不行了。\n",
      "未来的送快递的人买了包子。\n",
      "真的吗？你不行吗？\n",
      "美若天仙的送快递的人吃了丢了魂的未来的丢了魂的自然的火箭。\n",
      "我的妈呀？我也想这样吗？\n",
      "老公买了包子\n",
      "太牛逼了？这人亲眼见过吗？\n",
      "老板学习了咖啡\n",
      "哈哈哈？这人好厉害啊！\n",
      "美若天仙的送快递的人买了包子。\n",
      "少来这套？你相信吗？\n",
      "老板买了麻将。\n",
      "当老娘是吃素的？这人不行了。\n",
      "Tony老师买了包子\n",
      "哼？你相信吗？\n",
      "送快递的人打了儿子\n",
      "少来这套！我不行吗？\n",
      "老板买了儿子。\n",
      "哼？你相信吗？\n"
     ]
    }
   ],
   "source": [
    "myDialog = generate_n(20)\n",
    "for s in myDialog:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "mov_com = pd.read_csv('movie_comments.csv')\n",
    "mov_com.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "261497"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mov_com_com = mov_com['comment'].tolist()\n",
    "len(mov_com_com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "from collections import Counter\n",
    "\n",
    "def token(string):\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure_comments_list = [''.join(token(str(com))) for com in mov_com_com]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心', '想', '吐']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_comments_list[0]\n",
    "list(jieba.cut(pure_comments_list[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = []\n",
    "for i, com in enumerate(pure_comments_list):\n",
    "    TOKEN += list(jieba.cut(com))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_1 = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_gram = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]\n",
    "words_count_2 = Counter(TOKEN_2_gram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word_1, word_2, TOKEN, words_count):\n",
    "    if word_1 + word_2 in words_count:\n",
    "        return words_count[word_1 + word_2] / len(TOKEN)\n",
    "    else:\n",
    "        return 1 / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_sentence(sentence, TOKEN=TOKEN_2_gram, words_count=words_count_2):\n",
    "    word_list = list(jieba.cut(sentence))\n",
    "    sentence_prob = 1\n",
    "    \n",
    "    for i, word in enumerate(word_list[:-1]):\n",
    "        next_word = word_list[i + 1]\n",
    "        sentence_prob *= prob_2(word, next_word, TOKEN, words_count)\n",
    "    return sentence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['丢了魂的送快递的人打了麻将',\n",
       " '哈哈哈我好厉害吗',\n",
       " '送快递的人学习了咖啡',\n",
       " '少来这套这人服了了',\n",
       " '送快递的人买了美若天仙的隔壁的腐烂的咖啡',\n",
       " '哼你服了吗',\n",
       " '老公留下了咖啡',\n",
       " '吓死我了这人好厉害的',\n",
       " '老板打了香奈儿包包',\n",
       " '太牛逼了我亲眼见过啊',\n",
       " '送快递的人丢了钱',\n",
       " '我的妈呀我好厉害啊',\n",
       " '自然的丢了魂的未来的一百万的送快递的人吃了自然的钱',\n",
       " '当老娘是吃素的我服了的',\n",
       " '老公喝了包子',\n",
       " '哼我不行的',\n",
       " '送快递的人吃了骄傲的房子',\n",
       " '哼你也想这样吗',\n",
       " '老板喝了钱',\n",
       " '当老娘是吃素的你好厉害啊']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myDialog = generate_n(20)\n",
    "myCleanDialog = [''.join(token(dialog)) for dialog in myDialog]\n",
    "myCleanDialog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: 丢了魂的送快递的人打了麻将。 Prob: 1.1515839994503542e-54\n",
      "Sentence: 哈哈哈！我好厉害吗？ Prob: 6.534376206903757e-22\n",
      "Sentence: 送快递的人学习了咖啡。 Prob: 4.208763518749291e-34\n",
      "Sentence: 少来这套？这人服了了。 Prob: 6.641376156085126e-26\n",
      "Sentence: 送快递的人买了美若天仙的隔壁的腐烂的咖啡。 Prob: 2.1004668155962005e-70\n",
      "Sentence: 哼？你服了吗？ Prob: 5.897542026603592e-23\n",
      "Sentence: 老公留下了咖啡。 Prob: 7.95249184234847e-19\n",
      "Sentence: 吓死我了！这人好厉害的。 Prob: 7.84064160120078e-34\n",
      "Sentence: 老板打了香奈儿包包 Prob: 7.010341498089856e-25\n",
      "Sentence: 太牛逼了？我亲眼见过啊！ Prob: 2.285474783023752e-36\n",
      "Sentence: 送快递的人丢了钱。 Prob: 3.124688066950232e-32\n",
      "Sentence: 我的妈呀！我好厉害啊！ Prob: 2.1667758814258023e-29\n",
      "Sentence: 自然的丢了魂的未来的一百万的送快递的人吃了自然的钱。 Prob: 4.658710404903312e-97\n",
      "Sentence: 当老娘是吃素的？我服了的。 Prob: 6.216144055607036e-42\n",
      "Sentence: 老公喝了包子 Prob: 4.85985612587962e-19\n",
      "Sentence: 哼！我不行的。 Prob: 3.42398954323337e-17\n",
      "Sentence: 送快递的人吃了骄傲的房子！ Prob: 4.972681854399444e-43\n",
      "Sentence: 哼！你也想这样吗？ Prob: 6.497596623329114e-27\n",
      "Sentence: 老板喝了钱 Prob: 8.504748220289337e-18\n",
      "Sentence: 当老娘是吃素的？你好厉害啊！ Prob: 3.803584649409901e-44\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(myDialog)):\n",
    "    print('Sentence: {} Prob: {}'.format(myDialog[i], prob_sentence(myCleanDialog[i], TOKEN_2_gram, words_count_2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(gram, n=50, prob_sentence=prob_sentence):\n",
    "    sentences = []\n",
    "    for i in range(n):\n",
    "        sentence = generate_1(gram, target='sentence')\n",
    "        clean_sentence = ''.join(token(sentence))\n",
    "        prob = prob_sentence(clean_sentence)\n",
    "        sentences.append((sentence, prob))\n",
    "    sentences = sorted(sentences, key=lambda x:x[1], reverse=True)\n",
    "    return sentences[0]    # return a tuple (sentence, prob) with highest probability\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIDAGU: 小张留下了儿子。 (prob = 1.351924e-17)\n",
      "BADAYI: 哈哈哈？这人服了啊！ (prob = 5.699286e-18)\n",
      "QIDAGU: 老板喝了钱。 (prob = 8.504748e-18)\n",
      "BADAYI: 哼！我相信了。 (prob = 9.907479e-17)\n",
      "QIDAGU: 小张打了咖啡！ (prob = 3.147861e-18)\n",
      "BADAYI: 哼！我相信的。 (prob = 2.286341e-16)\n",
      "QIDAGU: 老王打了钱。 (prob = 1.101751e-16)\n",
      "BADAYI: 哈哈哈？我服了吗？ (prob = 5.394440e-17)\n",
      "QIDAGU: 老板丢了钱。 (prob = 2.706056e-17)\n",
      "BADAYI: 哈哈哈？我不信的。 (prob = 2.133919e-17)\n",
      "QIDAGU: 老王喝了儿子！ (prob = 4.130878e-18)\n",
      "BADAYI: 哈哈哈？我不行的。 (prob = 1.575035e-16)\n",
      "QIDAGU: 小张吃了儿子。 (prob = 2.647517e-17)\n",
      "BADAYI: 哈哈哈！我不信啊！ (prob = 7.113062e-18)\n",
      "QIDAGU: 小张吃了麻将。 (prob = 1.557363e-18)\n",
      "BADAYI: 哈哈哈？我不信了。 (prob = 2.133919e-17)\n",
      "QIDAGU: 老王买了钱！ (prob = 4.832243e-17)\n",
      "BADAYI: 哈哈哈？我相信啊！ (prob = 3.505723e-17)\n",
      "QIDAGU: 老板留下了钱。 (prob = 2.783372e-17)\n",
      "BADAYI: 哈哈哈！我不行啊！ (prob = 1.905285e-16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sentence, prob = generate_best(gram_qiDaGu)\n",
    "    print('QIDAGU: {} (prob = {:2e})'.format(sentence, prob))\n",
    "    sentence, prob = generate_best(gram_baDaYi)\n",
    "    print('BADAYI: {} (prob = {:2e})'.format(sentence, prob)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: \n",
    "The major problem rises from the assumption of 2-gram model. \n",
    "The probability of a word given certain history is replaced by the conditional probability of the preceding word.\n",
    "For example, the following sentence has a relatively high probability, which is obviously a bad sentence.\n",
    "\n",
    "Sentence: 老板喝了钱 Prob: 8.504748220289337e-18\n",
    "\n",
    "This is because '喝+了' and '了+钱' both have high probability. Perhaps they are often used like this, '喝+了+水' or '花+了+钱'.\n",
    "But '喝' and '钱' can never be linked through '了'.\n",
    "So we may need to increase the number of preceding words for calculating the conditional probability, which means more history should be checked, and 3-gram or 4-gram can be a better choice.\n",
    "\n",
    "The other problem is that it is less likely to generate a long sentence. \n",
    "A long sentence tends to have a lower probability than a short sentence.\n",
    "Instead of using raw probability as the metric to select sentences, one may use some averged probability by taking into account the numbers of words. \n",
    "Perplexity, defined as PP(W) = P(w1w2w3...wN) ** (-1/N), can be used as a metric for sentence selection.\n",
    "The following two cells show a revised version of generate_best using perplexity. It does not improve the probability of long sentences for QIDAGU grammar, but there are more longer sentences for BADAYI grammar. This is probably because BADAYI is designed to make sense more frequently than QIDAGU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "def generate_best_2(gram, n=50, prob_sentence=prob_sentence):\n",
    "    sentences = []\n",
    "    for i in range(n):\n",
    "        sentence = generate_1(gram, target='sentence')\n",
    "        clean_sentence = ''.join(token(sentence))\n",
    "        prob = prob_sentence(clean_sentence)\n",
    "        num_word = len(list(jieba.cut(clean_sentence)))\n",
    "        sentences.append((sentence, (1 / prob)**(1 / num_word)))\n",
    "    sentences = sorted(sentences, key=lambda x:x[1], reverse=False)\n",
    "    return sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QIDAGU: 老公吃了钱。 (prob = 1.163819e+04)\n",
      "BADAYI: 太牛逼了？我也想这样的。 (prob = 3.980877e+03)\n",
      "QIDAGU: 老板留下了儿子！ (prob = 1.649157e+04)\n",
      "BADAYI: 吓死我了？你也想这样的。 (prob = 6.506177e+03)\n",
      "QIDAGU: 老板买了钱！ (prob = 1.199397e+04)\n",
      "BADAYI: 太牛逼了？我好厉害了。 (prob = 5.300704e+03)\n",
      "QIDAGU: 老公丢了钱！ (prob = 1.386487e+04)\n",
      "BADAYI: 太牛逼了！你不行了。 (prob = 9.224088e+03)\n",
      "QIDAGU: 老公喝了钱。 (prob = 1.851760e+04)\n",
      "BADAYI: 太牛逼了？我也想这样的。 (prob = 3.980877e+03)\n",
      "QIDAGU: 小张买了儿子。 (prob = 1.436705e+04)\n",
      "BADAYI: 哈哈哈？我也想这样的。 (prob = 4.315999e+03)\n",
      "QIDAGU: 小张打了钱！ (prob = 9.760658e+03)\n",
      "BADAYI: 真的吗！我也想这样的。 (prob = 6.340734e+03)\n",
      "QIDAGU: 小张丢了儿子。 (prob = 1.660812e+04)\n",
      "BADAYI: 吓死我了！我不行的。 (prob = 6.887391e+03)\n",
      "QIDAGU: 老王吃了钱。 (prob = 1.163819e+04)\n",
      "BADAYI: 太牛逼了！我也想这样的。 (prob = 3.980877e+03)\n",
      "QIDAGU: 老公丢了儿子。 (prob = 1.660812e+04)\n",
      "BADAYI: 吓死我了？我好厉害的。 (prob = 5.832910e+03)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    sentence, prob = generate_best_2(gram_qiDaGu)\n",
    "    print('QIDAGU: {} (prob = {:2e})'.format(sentence, prob))\n",
    "    sentence, prob = generate_best_2(gram_baDaYi)\n",
    "    print('BADAYI: {} (prob = {:2e})'.format(sentence, prob)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
